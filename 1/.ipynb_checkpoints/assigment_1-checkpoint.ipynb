{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8636ee53",
   "metadata": {},
   "source": [
    "# Assignment 1:\n",
    "The assignment consists in the development, in NLTK, OpenNLP, SketchEngine or GATE/Annie a Naïve Bayes Classifier able to detect a single class in one of the corpora available as attachments to the chosen package, by distinguishing ENGLISH against NON-ENGLISH. In particular the classifier has to be:\n",
    "\n",
    "- Trained on a split subset of the chosen corpus, by either using an existing partition between sample documents for training and for test or by using a random splitter among the available ones;\n",
    "\n",
    "- Devised as a pipeline of any chosen format, including the simplest version based on word2vec on a list of words obtained by one of the available lexical resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9762502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************ IMPORTS ************************#\n",
    "import nltk\n",
    "import asyncio\n",
    "import random\n",
    "import math \n",
    "import collections\n",
    "from tqdm import tqdm \n",
    "# from sklearn import f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0bc21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import europarl_raw # Euro Parlamentars speeches \n",
    "from nltk.corpus import state_union as union # America's presidents Union Day speeches \n",
    "# CORPUS DATA \n",
    "\n",
    "# Creating iterators containing all the needed file ids\n",
    "en_ids = [fileid for fileid in europarl_raw.english.fileids()]\n",
    "dutch_ids = [fileid for fileid in europarl_raw.dutch.fileids()]\n",
    "fr_ids = [fileid for fileid in europarl_raw.french.fileids()]\n",
    "union_ids = [fileid for fileid in union.fileids()]\n",
    "\n",
    "# Loading ENGLISH euro_parlcorpora and adding the English label \n",
    "documents= [(europarl_raw.english.raw(fileid), \"English\") for fileid in en_ids]\n",
    "\n",
    "# Loading America's union speechs corpora and adding the English label \n",
    "for fileid in union_ids:\n",
    "    documents.append((union.raw(fileid) , \"English\"))\n",
    "\n",
    "# Loading FRENCH corpora and  label \n",
    "for fileid in fr_ids:\n",
    "    documents.append((europarl_raw.french.raw(fileid) , \"NonEnglish\"))\n",
    "    \n",
    "# Loading DUTCH corpora and respective label \n",
    "for fileid in dutch_ids:\n",
    "    documents.append((europarl_raw.dutch.raw(fileid) , \"NonEnglish\"))\n",
    "    \n",
    "random.shuffle(documents)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8efeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))  \n",
    "stop_words.add(word for word in stopwords.words(\"french\"))\n",
    "stop_words.add(word for word in stopwords.words(\"dutch\"))\n",
    "\n",
    "# STEMMER \n",
    "from nltk.stem import PorterStemmer \n",
    "stemmer = PorterStemmer()  \n",
    "\n",
    "# LEMMATIZER\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c93b39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 95/95 [00:55<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZATION, LEMMATIZING, STEMMMING AND STOP WORDS REMOVAL \n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "fdist = FreqDist() # freqdist to keep counting w instances for creating BOW \n",
    "data = [0 for _ in range(len(documents))]\n",
    "\n",
    "for i,(text,label) in enumerate(tqdm(documents)):\n",
    "    appo = ([],label)\n",
    "\n",
    "    sents = sent_tokenize(text)\n",
    "    for sent in sents:\n",
    "        words = word_tokenize(sent) \n",
    "        for word in words:\n",
    "            if word.casefold() not in stop_words:\n",
    "                stemmed = stemmer.stem(word.lower()) # Stemming \n",
    "                lemmatized = lemmatizer.lemmatize(stemmed) # Lemmatization\n",
    "                fdist[lemmatized] += 1 # Increases Word Counter inside the Bag of Words\n",
    "                appo[0].append(lemmatized) # Saves the Result\n",
    "\n",
    "    data[i] = appo \n",
    "top_words = list(fdist)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b71454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 95/95 [00:00<00:00, 410.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction: \n",
    "def feature_estractor(document,top_words):\n",
    "    document_set = set(document)\n",
    "    features = {}\n",
    "    for word in top_words:\n",
    "        features['contains({})'.format(word)] = (word in document_set)\n",
    "    return features\n",
    "\n",
    "featuresets = [(feature_estractor(d,top_words), c) for (d,c) in tqdm(data)]\n",
    "train_test_split = math.floor(len(featuresets) * 0.7 )\n",
    "train_set, test_set = featuresets[:train_test_split], featuresets[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6cdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec162839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing and Metrics: \n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 score: 1.0\n",
      "           |             N |\n",
      "           |             o |\n",
      "           |             n |\n",
      "           |      E      E |\n",
      "           |      n      n |\n",
      "           |      g      g |\n",
      "           |      l      l |\n",
      "           |      i      i |\n",
      "           |      s      s |\n",
      "           |      h      h |\n",
      "-----------+---------------+\n",
      "   English | <86.2%>     . |\n",
      "NonEnglish |      . <13.8%>|\n",
      "-----------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Most Informative Features\n",
      "          contains(also) = False          NonEng : Englis =     33.0 : 1.0\n",
      "          contains(come) = False          NonEng : Englis =     33.0 : 1.0\n",
      "       contains(countri) = False          NonEng : Englis =     33.0 : 1.0\n",
      "           contains(day) = False          NonEng : Englis =     33.0 : 1.0\n",
      "            contains(en) = True           NonEng : Englis =     33.0 : 1.0\n",
      "         contains(everi) = False          NonEng : Englis =     33.0 : 1.0\n",
      "          contains(hope) = False          NonEng : Englis =     33.0 : 1.0\n",
      "          contains(make) = False          NonEng : Englis =     33.0 : 1.0\n",
      "        contains(member) = False          NonEng : Englis =     33.0 : 1.0\n",
      "        contains(milieu) = True           NonEng : Englis =     33.0 : 1.0\n",
      "          contains(must) = False          NonEng : Englis =     33.0 : 1.0\n",
      "            contains(pa) = True           NonEng : Englis =     33.0 : 1.0\n",
      "          contains(peac) = False          NonEng : Englis =     33.0 : 1.0\n",
      "          contains(work) = False          NonEng : Englis =     33.0 : 1.0\n",
      "         contains(would) = False          NonEng : Englis =     33.0 : 1.0\n",
      "         contains(peopl) = False          NonEng : Englis =     31.0 : 1.0\n",
      "       contains(premier) = True           NonEng : Englis =     31.0 : 1.0\n",
      "         contains(state) = False          NonEng : Englis =     31.0 : 1.0\n",
      "         contains(today) = False          NonEng : Englis =     31.0 : 1.0\n",
      "          contains(unit) = False          NonEng : Englis =     31.0 : 1.0\n",
      "           contains(fin) = True           NonEng : Englis =     29.0 : 1.0\n",
      "            contains(je) = True           NonEng : Englis =     29.0 : 1.0\n",
      "          contains(time) = False          NonEng : Englis =     27.0 : 1.0\n",
      "         contains(world) = False          NonEng : Englis =     25.0 : 1.0\n",
      "         contains(erika) = True           NonEng : Englis =     21.0 : 1.0\n",
      "      contains(progress) = False          NonEng : Englis =     21.0 : 1.0\n",
      "      contains(american) = False          NonEng : Englis =     19.8 : 1.0\n",
      "           contains(dan) = True           NonEng : Englis =     19.8 : 1.0\n",
      "          contains(give) = False          NonEng : Englis =     19.8 : 1.0\n",
      "          contains(live) = False          NonEng : Englis =     19.8 : 1.0\n",
      "           contains(may) = False          NonEng : Englis =     19.8 : 1.0\n",
      "          contains(need) = False          NonEng : Englis =     19.8 : 1.0\n",
      "          contains(next) = False          NonEng : Englis =     19.8 : 1.0\n",
      "         contains(secur) = False          NonEng : Englis =     19.8 : 1.0\n",
      "        contains(strong) = False          NonEng : Englis =     19.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.scores import (precision, recall)\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "print(\"Testing and Metrics: \")\n",
    "refsets =  collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "labels = []\n",
    "tests = []\n",
    "for i,(feats,label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    result = classifier.classify(feats)\n",
    "    testsets[result].add(i)\n",
    "    labels.append(label)\n",
    "    tests.append(result)\n",
    "    #print(\"True value: \"+label+\" Our value: \"+result)\n",
    "    \n",
    "cm = ConfusionMatrix(labels, tests)\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "prec = precision(refsets['English'], testsets['English'])\n",
    "print( 'Precision:', prec )\n",
    "rec = recall(refsets['English'], testsets['English'])\n",
    "print( 'Recall:', rec )\n",
    "f1 = 2 *(prec*rec)/(prec+rec)\n",
    "print(\"F1 score:\", f1)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))\n",
    "classifier.show_most_informative_features(35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e8aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 1: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 2: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 3: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 4: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 5: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 6: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 7: Our_result => NonEnglish True_result => NonEnglish\n",
      "Right Value\n",
      "\n",
      "Sample 8: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 9: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 10: Our_result => NonEnglish True_result => NonEnglish\n",
      "Right Value\n",
      "\n",
      "Sample 11: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 12: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 13: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 14: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 15: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 16: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 17: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 18: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 19: Our_result => NonEnglish True_result => NonEnglish\n",
      "Right Value\n",
      "\n",
      "Sample 20: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 21: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 22: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 23: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 24: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 25: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 26: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 27: Our_result => English True_result => English\n",
      "Right Value\n",
      "\n",
      "Sample 28: Our_result => NonEnglish True_result => NonEnglish\n",
      "Right Value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lenght = len(test_set)\n",
    "for i in range(lenght):\n",
    "    test = test_set[i]\n",
    "    print(f\"Sample {i}: Our_result => {classifier.classify(test[0])} True_result => {test[1]}\")\n",
    "    if classifier.classify(test[0]) == test[1] :\n",
    "        print(\"Right Value\\n\")\n",
    "    else:\n",
    "        print(\"Wrong Value\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40aad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
